---
title: "[데이터 중심 애플리케이션 설계] 1장 Summary"
date: "2023-10-12 00:02:13"
description: "신뢰성, 확장성, 유지보수성"
category: "Reading"
draft: false
---

## 데이터 중심(Data-intensive) 애플리케이션

- 오늘날 많은 애플리케이션은 Compute-intensive하기 보다는 Data-intensive
- CPU 성능보다도 데이터의 양, 복잡도, 변화 속도가 더 크고 중요한 문제가 되었다는 의미
- 일반적인 데이터 중심 애플리케이션의 구성 요소들
    - 데이터베이스 : 데이터를 다시 찾을 수 있도록 저장
    - 캐시 : 읽기 속도 향상을 위해 수행 결과를 기억
    - 검색 색인(Search Index) : 키워드로 데이터를 검색하거나 다양한 방법으로 필터링할 수 있는 기능 제공
    - 스트림 처리 : 비동기 처리를 위해 다른 프로세스로 메시지 보내기
    - 일괄 처리(Batch Processing) : 주기적으로 대량의 누적 데이터를 분석
- 애플리케이션의 요구 사항에 따라 적절한 데이터 시스템을 구축해야 함
    - 캐싱을 위한 다양한 접근 방법, 검색 색인의 구축 등 어떤 도구와 어떤 접근 방식이 가장 적합한지
    - 여러 도구의 결합
    - 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 데이터 시스템의 구축

## 데이터 시스템

- 데이터베이스, 큐, 캐시, …
    - 새로운 도구들은 이런 전통적인 분류에 딱 맞지는 않음 (Redis는 메시지 큐로 사용 가능하면서 데이터스토어, 카프카는 데이터베이스처럼 지속성을 보장하면서 메시지 큐)
    - 여러 도구들을 결합해 사용하는 경우가 많아지고 있으며, 애플리케이션 코드를 통해 결합 (e.g. 메인 데이터베이스와 캐시의 동기화를 애플리케이션 코드를 통해 수행)
- 데이터 시스템 및 서비스 설계와 관련된 문제들
    - 내부적으로 문제가 있어도 데이터를 정확하고 완전하게 유지하려면 어떻게 해야 할까?
    - 시스템의 일부 성능이 저하되더라도 클라이언트에 일관되게 좋은 성능을 어떻게 제공할 수 있을까?
    - 부하 증가를 다루기 위해 어떻게 규모를 확장할까?
    - 서비스를 위해 좋은 API는 어떤 모습일까?

## 신뢰성, 확장성, 유지보수성

### 신뢰성(Reliability)

- 다양한 역경(하드웨어 결함, 소프트웨어 결함, 인적 오류)에 직면하더라도 시스템이 지속적으로 올바르게 동작(원하는 성능 수준에서 정확한 기능 수행)
- 원자력 발전소나 항공 관세 소프트웨어가 아니더라도, 일상적인 애플리케이션에서도 신뢰성은 필요하며 생산성, 매출, 명성 및 책임에 있어 매우 중요
- 일반적으로 소프트웨어를 신뢰할 수 있다는 것은 아래와 같은 기대치가 존재
    - 애플리케이션은 사용자가 기대한 기능을 수행한다.
    - 시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다.
    - 시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다.
    - 시스템은 허가되지 않은 접근과 오남용을 방지한다.
- 무언가 잘못되더라도 올바르게 동작 → 결함을 예측하고 대처할 수 있는 시스템
    - 결함(fault) : 잘못될 수 있는 일 (≠ 장애(failure) : 시스템이 멈춘 경우)
    - 내결함성(fault-tolerant) / 탄력성(resilient) : 결함을 예측하고 대처할 수 있는가
    - 결함으로 인한 장애가 발생하지 않도록 내결함성 구조를 설계해야 함
    - 넷플릭스의 카오스 몽키 사례 : 고의적으로 결함을 유도함으로써 내결함성 시스템을 지속적으로 훈련하고 테스트, 카오스 엔지니어링(http://principlesofchaos.org/ko/)
- 하드웨어 결함
    - 예시 : 하드디스크 고장, 램 결함, 대규모 정전, 네트워크 케이블 문제 등등
    - 하드웨어 구성 요소 **중복**을 통한 대응
        - 디스크 RAID 구성
        - 서버 이중 전원, 핫 스왑 가능한 CPU
        - 하드웨어 결함율이 증가하고 클라우드 인스턴스의 경우 중지되는 경우가 잦아, 소프트웨어 내결함성 기술을 사용하거나 하드웨어 중복성을 늘린 시스템이 점점 사용되고 있음
- 소프트웨어 결함
    - 예시
        - 잘못된 특정 입력에 의해 모든 애플리케이션 서버 인스턴스가 죽는 소프트웨어 버그 (2021년 6월 30일 윤초에 대한 리눅스 커널 버그)
        - CPU 시간, 메모리, 디스크 공간, 네트워크 대역폭 같은 공유 자원을 과도하게 사용하는 일부 프로세스
        - 시스템의 속도가 느려져 반응이 없거나 잘못된 응답을 반환하는 서비스
        - 한 구성 요소의 작은 결함이 다른 구성 요소들의 결함을 야기하는 연쇄 장애
    - 노드 간 상관관계가 있어, 그렇지 않은 하드웨어 결함보다 더 많은 오류가 유발되는 경향이 있음
- 인적 오류
    - 사람이 설계, 구축, 운영하면서 생기는 오류들
    - 최대한 신뢰성 있는 시스템을 만들기 위한 접근 방식
        - 오류의 가능성을 최소화하는 방향으로 시스템 설계 : 잘 설계된 추상화, API, 관리 인터페이스
        - 사람의 실수로 장애가 발생할 수 있는 부분을 분리하기
        - 단위 테스트, 전체 시스템 통합 테스트, 수동 테스트 등 모든 수준에서 철저한 테스트
        - 인적 오류를 빠르고 쉽게 복구할 수 있게 : 설정 변경 내역을 빠르게 롤백, 새로운 코드를 서서히 롤아웃, 데이터 재계산 도구
        - 성능 지표와 오류율 등 모니터링
        - 조작 교육과 실습

### 확장성(Scalability)

- 시스템의 데이터 양, 트래픽 양, 복잡도가 증가할 때 이를 적절히 처리
- 동시 사용자 수가 1만명에서 1000만명으로 증가하고, 더 많은 데이터를 시스템에서 처리해야 할 때 증가한 부하에 대처하는 시스템 능력
- 시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가? 추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?
- 부하 기술하기
    - 적합한 부하 매개변수를 선택하여 부하를 기술 (웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자, 캐시 적중률 등)
    - 트위터 사례
        - 트위터의 두 가지 동작
            - 트윗 작성 : 팔로워에게 새로운 메시지 게시 (평균 초당 4.6k 요청, 피크일 때 초당 12k 이상 요청)
            - 홈 타임라인 : 팔로우한 사람이 작성한 트윗을 볼 수 있음 (초당 300k 요청)
        - 접근 방식
            - A : 트윗 작성 시 tweets 테이블에 삽입하고, 타임라인 조회 시 사용자와 팔로워 테이블을 조인하여 팔로우 하는 사람들의 트윗들을 조회
                - 트윗 작성보다 홈 타임라인 조회에 대한 비용이 큼
            - B : 트윗 작성 시 해당 사용자를 팔로우하는 사람들의 홈 타임라인 캐시에 트윗을 삽입, 홈 타임라인 조회 시 캐시에서 내용을 가져옴
                - 홈 타임라인 조회는 비용이 저렴하지만 트윗 작성의 비용이 큼
                - 트윗 작성 시 모든 팔로워들의 타임라인 캐시에 트윗을 전달해야 하는 팬 아웃 발생 (팬 아웃 : 트랜잭션 처리 시스템에서 하나의 수신 요청을 처리하기 위해 필요한 다른 서비스 요청 수를 설명하는 단어)
        - 초기에는 A 접근 방식을 사용했으나, 홈 타임라인 질의 부하가 커 B로 전환하였음
        - 홈 타임라인 조회가 훨씬 많은 요청량을 가짐
        - 평균의 함정 : 사용자마다 팔로워 수가 매우 다르며, 팔로워가 3천만 명이 넘는 사용자들도 있음 → 하나의 트윗 작성 요청이 3천만 건 이상의 팬 아웃으로 이어짐
        - 최종적인 트위터의 접근 방식
            - 두 방식의 하이브리드
            - 기본적으로 접근 방식 B를 사용하지만, 팔로워 수가 매우 많은 소수 사용자들은 제외됨
            - 팔로워 수가 많은 사용자들의 트윗은 접근 방식 A처럼 홈 타임라인을 읽는 시점에 따로 가져와 합치는 방식
- 부하 기술 후 → 성능 기술하기
    - 시스템 부하가 증가했을 때의 성능 영향
        - 부하 매개변수를 증가시키고 시스템 자원을 유지했을 때 시스템 성능은 어떻게 영향을 받을까?
        - 부하 매개변수를 증가시키고 시스템 성능을 유지하려면 시스템 자원을 얼마나 늘려야 할까?
    - 성능 수치
        - 처리량(Throughput), 응답 시간(Response time), 지연 시간(Latency) 등
        - 온라인 시스템에서는 응답 시간(클라이언트가 요청을 보내고 받는 사이의 시간)이 중요한 요소
        - 전형적인, 얼마나 많은 사용자들이 실제로 지연을 경험했는지에 대한 지표로는 평균 응답 시간보다는 백분위를 보는 것이 좋음
            - 사용자가 보통 얼마나 오래 기다려야 하는가 : 중앙값(p50)
            - 특이 값이 얼마나 좋지 않은지 : 상위 백분위(p95, p99, p999)
            - 상위 백분위 응답 시간은 꼬리 지연 시간(Tail Latency)라고도 하며, 사용자 경험에 직접 영향을 주는 중요한 요소
            - 아마존 사례 : 응답 시간 요구 사항을 p999로 기술하는데, 요청 1000개 중 가장 느린 1개의 사용자는 많은 구매를 해서 계정에 많은 데이터를 갖고 있는 소중한 고객들이기 때문. 응답 시간이 100밀리초 증가하면 판매량이 1% 줄어들고, 1초가 느려지면 고객 만족도 지표는 16% 줄어드는 현상이 있었다고 함. 반면 p9999를 최적화하는 작업은 비용이 너무 많이 들어 충분한 이익이 되지 않는다고 판단하며, 최상위 백분위는 통제할 수 없는 임의 이벤트에 쉽게 영향을 받아 줄이기 매우 어려움.
            - 서비스 수준 목표(Service Level Objective, SLO) 및 서비스 수준 협약서(Service Level Agreement, SLA)에서도 백분위가 자주 사용됨 (e.g. 응답 시간 중앙값이 200ms 미만이고 99분위가 1초 미만인 경우 정상 서비스 상태로 간주하며 서비스 제공 시간은 99.99% 이상이어야 한다)
        - 높은 백분위의 소수 느린 요청이 다른 요청의 응답 시간에도 영향을 줌
            - 서버는 병렬로 소수의 작업만 처리할 수 있기에, 소수의 느린 요청들로 발생하는 큐 대기 지연(Queueing delay)로 인해 후속 요청들의 처리가 지연됨. 이런 현상을 선두 차단(head-of-line blocking)이라고도 하며, 후속 요청이 빠르게 처리되더라도 이전 요청을 기다리는 시간 때문에 클라이언트 입장에서는 응답 시간이 느리다고 생각하게 됨. 클라이언트 쪽 응답 시간 측정이 중요한 이유.
            - 꼬리 지연 증폭 : 병렬로 호출하더라도 최종 사용자 요청을 완료하려면 병렬 요청들 중 꼬리 지연에 해당하는 가장 느린 요청이 완료되길 기다려야 함.
        - 서비스의 모니터링 대시보드에 응답 시간 백분위를 추가하려면 지속적으로 백분위를 효율적으로 계산해야 하며, 예를 들어 지난 10분 동안의 응답 시간을 롤링 윈도로 유지하는 경우가 있음. 단순한 구현으로 시간 내 모든 요청의 응답 시간 목록을 유지하면서 1분마다 목록을 정렬하는 방법이 있으며, 상황에 따라 더 효율적인 알고리즘으로 Forward decay, T-digest, HdrHistogram 등을 사용할 수 있음.
        - 시스템 확장성을 테스트하기 위해 인위적으로 부하를 생성하는 경우, 부하 생성 클라이언트는 응답 시간과 독립적으로 요청을 지속적을 보내야 함. 즉, 이전 요청에 대한 응답이 오길 기다렸다가 다음 요청을 보내는 것이 아님.
- 부하 대응 접근 방식
    - 확장성
        - 용량 확장(Scaling up, Vertical scailing) : 더 강력한 장비로 이동
        - 규모 확장(Scaling out, Horizontal scailing) : 다수의 장비에 부하 분산 (비공유 아키텍처)
        - 고사양 장비는 매우 비싸기 때문에 대개 규모 확장을 피하지 못하며, 현실적으로 좋은 아키텍처는 실용적인 접근 방식의 조합이 필요
    - 탄력적(elastic)
        - 부하를 감지하면 자동으로 컴퓨팅 자원을 추가 (↔ 사람이 분석하여 수동으로 시스템을 확장)
        - 부하가 예측 불가능하게 높은 경우 유용하지만, 수동 확장 시스템이 더 간단하고 운영상 예상치 못한 일이 더 적음
    - 데이터 시스템의 분산
        - Stateless 서비스를 분산 배포하는 것은 비교적 간단하나, 데이터 시스템의 분산은 복잡도가 커 고가용성 요구가 있기 전에는 단일 데이터베이스에서 용량 확장을 하는 것이 통념
        - 분산 시스템을 위한 도구와 추상화가 좋아지면서, 대용량 트래픽을 다루지 않는 사용 사례에도 분산 데이터 시스템이 향후 기본 아키텍처로 자리 잡을 가능성은 있음
    - 애플리케이션에 적합한 확장성을 갖춘 아키텍처
        - 주요 동작이 무엇이고, 잘 하지 않는 동작은 무엇인지에 대한 가정이 바탕이 되며, 이는 부하 매개변수로 나타남
        - 읽기의 양, 쓰기의 양, 저장할 데이터의 양, 데이터의 복잡도, 응답 시간 요구사항, 접근 패턴 등이 아키텍처를 결정함
        - 범용적이고 모든 상황에 맞는 확장 아키텍처는 없음 (e.g. 크기가 1kB인 초당 100,000건의 요청을 처리하도록 설계한 시스템 vs. 크기가 2GB인 분당 3건의 요청을 처리하도록 설계한 시스템)
        - 아키텍처의 확장은 특정 애플리케이션에 특화되지만, 아키텍처는 익숙한 패턴으로 나열된 범용적인 구성 요소들로 구축됨

### 유지보수성(Maintainability)

- 시간이 지나며 다양한 사람들이 현재 시스템을 유지보수하고 새로운 사용 사례를 시스템에 적용하는데, 모든 사람들이 시스템 상에서 생산적으로 작업할 수 있음
- 소프트웨어 비용의 대부분은 초기 개발보다 지속적인 유지보수에 들어감
    - 버그 수정, 시스템 운영 유지, 장애 조사, 새로운 플랫폼 적응, 새 사용 사례를 위한 변경, 기술 채무 상환, 새로운 기능 추가 등
- 유지보수의 고통을 최소화하고 레거시 소프트웨어를 직접 만들지 않기 위한 **소프트웨어 시스템 설계 원칙**
    - 운용성(Operability)
        - 운영팀이 시스템을 원활하게 운영할 수 있도록 (운영의 편리함 만들기)
        - 동일하게 반복되는 태스크를 자동화하거나 쉽게 하기 위해서…
            - 좋은 모니터링으로 런타임 동작 및 시스템 내부에 대한 가시성 제공
            - 표준 도구를 이용해 자동화와 통합을 위한 우수한 자원 제공
            - 개별 장비 의존성을 회피 (유지보수를 위해 해당 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함)
            - 좋은 문서와 이해하기 쉬운 운영 모델(e.g. X하면 Y가 발생한다) 제공
            - 만족할 만한 기본 동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여
            - 적절히 자기 회복이 가능하며 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게
            - 예측 가능하게 행동하고 예기치 않은 상황 최소화
    - 단순성(Simplicity)
        - 시스템에서 복잡도를 최대한 줄여 새로운 엔지니어가 시스템을 이해하기 쉽도록 (복잡도 관리)
        - 복잡도가 나타나는 증상의 예시
            - 상태 공간의 급증, 모듈 간 강한 커플링, 복잡한 의존성, 일관성 없는 명명과 용어, 성능 문제 해결을 위한 해킹, 임시방편으로 문제를 해결한 특수 사례 등
        - 높은 복잡도는 작업을 지연시키고 유지보수 비용을 증가시키며 변경이 있을 때 버그의 위험을 증가시킴
        - 우발적 복잡도 : 소프트웨어가 풀어야 할 (사용자에게 보이는) 문제에 내재되지 않고 구현에서만 발생하는 복잡도
            - 적절한 추상화는 우발적 복잡도를 낮출 수 있음 (세부 구현을 숨기며, 재사용 가능)
            - e.g. 고수준 프로그래밍 언어는 기계어, 레지스터, 시스템 호출을 숨긴 추상화
            - 무엇이 좋은 추상화인가?
    - 발전성(Evolvability)
        - 엔지니어가 이후에 시스템을 쉽게 변경할 수 있도록 (변화를 쉽게 만들기)
        - 유연성(Extensibility), 수정 가능성(Modifiability), 적응성(Plasticity)
        - 시스템의 요구 사항은 끊임 없이 변화함 (새로운 사용 사례의 적용, 비즈니스 우선 순위의 변경, 새로운 기능 추가, 새로운 플랫폼이 기존 플랫폼을 대체, 법적 또는 규제 요구사항이 변경, 시스템 성장으로 인한 아키텍처 변화 등) → 변화에 적응해야 함
        - 애자일 작업 패턴에서는 TDD, 리팩토링 등 기술 도구와 패턴을 개발하여 민첩성 있게 변화에 적응하기 위한 프레임워크를 제공하지만, 대부분 작은 규모 시스템에 초점을 맞추고 있음
        - 데이터 시스템 변경을 쉽게 하는 것은 시스템의 간단함과 추상화와 관련이 있으며, 간단하고 이해하기 쉬운 시스템은 더 수정하기가 쉬움